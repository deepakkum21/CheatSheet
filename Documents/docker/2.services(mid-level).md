# Services
1. In a distributed application, **different pieces of the app are called “services”**. 
    - For example, if you imagine a video sharing site, it probably includes a service for storing application data in a database, a service for video transcoding in the background after a user uploads something, a service for the front-end, and so on.
2. **Services are really just “containers in production.”** 
3. A service **only runs one image**, but it codifies the way that image runs—**what ports it should use, how many replicas of the container** should run so the service has the capacity it needs, and so on. 
4. Scaling a service changes the number of container instances running that piece of software, assigning more computing resources to the service in the process.    
5. It’s very easy to define, run, and scale services with the Docker platform -- just write a ` docker-compose.yml` file.

## first docker-compose.yml file
1. A `docker-compose.yml` file is a YAML file that **defines how Docker containers should behave in production**.
2. Create a docker-compose.yml file
    -               version: "3"
                    services:
                    web:
                        # replace username/repo:tag with your name and image details
                        image: username/repo:tag
                        deploy:
                        replicas: 5
                        resources:
                            limits:
                            cpus: "0.1"
                            memory: 50M
                        restart_policy:
                            condition: on-failure
                        ports:
                        - "4000:80"
                        networks:
                        - webnet
                    networks:
                    webnet:
3. Save this file as docker-compose.yml wherever you want. Be sure you have pushed the image you created to a registry, and **update this .yml by replacing username/repo:tag with your image details.**
4. This `docker-compose.yml` file tells Docker to do the following:
    - Pull the image we uploaded in repo from the registry.
    - Run 5 instances of that image as a service called web, limiting each one to use, at most, 10% of the CPU (across all cores), and 50MB of RAM
    - Immediately restart containers if one fails.
    - Map port 4000 on the host to web’s port 80.
    - Instruct web’s containers to share port 80 via a load-balanced network called webnet. (Internally, the containers themselves publish to web’s port 80 at an ephemeral port.)
    - Define the webnet network with the default settings (which is a load-balanced overlay network).

## Run your new load-balanced app
1. we first run: `docker swarm init   --advertise-addr $(docker-machine ip)`
2. Now let’s run it. You need to give your app a name. Here, it is set to getstartedlab:
`docker stack deploy -c docker-compose.yml app-name`

## To list all services
`docker service ls`
- Look for output for the **web service, prepended with your app name**. If you named it the same as shown in this example, the name is getstartedlab_web. 
- The **service ID is listed as well, along with the number of replicas, image name, and exposed ports**.
- **A single container running in a service is called a task.** Tasks are given unique IDs that numerically increment, up to the number of replicas you defined in docker-compose.yml. 

## List the tasks for your service:
`docker service ps getstartedlab_web`

## Scale the app
- You can scale the app by changing the replicas value in docker-compose.yml, saving the change, and re-running the docker stack deploy command:
`docker stack deploy -c docker-compose.yml getstartedlab`

##v Take down the app and the swarm
- **Take the app down with docker stack rm:**
`docker stack rm getstartedlab`
- **Take down the swarm.**
`docker swarm leave --force`